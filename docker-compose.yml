services:
  postgres:
    image: postgres:latest
    container_name: postgres-container
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    ports:
      - "5432:5432"
    volumes:
      - alpha-vantage-data-pipeline_postgres_data:/var/lib/postgresql/data

  redis:    # Fixed indentation here
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: airflow-webserver
    restart: always
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@${DB_HOST}/${DB_NAME}
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}/${DB_NAME}
      AIRFLOW__CORE__BASE_URL: "http://localhost:8080"  # Ensure this is set correctly with http:// or https://
      AIRFLOW__WEBSERVER__WEB_SERVER_BASE_URL: "http://airflow-webserver:8080"  # Use http:// or https:// depending on your setup
      AIRFLOW__WEBSERVER__RBAC: 'True'
      AIRFLOW__WEBSERVER__DEFAULT_USER: ${AIRFLOW_USER}
      AIRFLOW__WEBSERVER__DEFAULT_PASSWORD: ${AIRFLOW_PASSWORD}
      AIRFLOW__CORE__LOGGING_CONFIG_FILE: /opt/airflow/logging_config.yaml
    ports:
      - "8080:8080"  # Airflow web interface
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs  # Log volume to persist logs
      - ./logging_config.yaml:/opt/airflow/logging_config.yaml
      - .env:/opt/airflow/.env
    command: ["bash", "-c", "airflow db upgrade && airflow users create -r Admin -u ${AIRFLOW_USER} -p ${AIRFLOW_PASSWORD} -e code66698@gmail.com@gmail.com -f admin -l user && airflow webserver"]

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: airflow-scheduler
    restart: always
    depends_on:
      - postgres
      - airflow-webserver
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@${DB_HOST}/${DB_NAME}
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}/${DB_NAME}
      AIRFLOW__CORE__LOGGING_CONFIG_FILE: /opt/airflow/logging_config.yaml
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs  # Log volume to persist logs
      - ./logging_config.yaml:/opt/airflow/logging_config.yaml
      - .env:/opt/airflow/.env
    command: ["airflow", "scheduler"]

  airflow-worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: airflow-worker
    restart: always
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@${DB_HOST}/${DB_NAME}
      AIRFLOW__CORE__BASE_URL: "http://localhost:8080"
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}/${DB_NAME}
      AIRFLOW__CORE__LOGGING_CONFIG_FILE: /opt/airflow/logging_config.yaml
      AIRFLOW__CELERY__WORKER_LOG_SERVER_PORT: 8793
      AIRFLOW__CORE__REMOTE_BASE_LOG_FOLDER: "http://airflow-worker:8793"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs  # Log volume to persist logs
      - ./logging_config.yaml:/opt/airflow/logging_config.yaml
      - .env:/opt/airflow/.env
    command: ["airflow", "celery", "worker"]

volumes:
  alpha-vantage-data-pipeline_postgres_data:
  airflow_dags: